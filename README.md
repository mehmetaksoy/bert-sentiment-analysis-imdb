# BERT ile Metin SÄ±nÄ±flandÄ±rma: IMDB Duygu Analizi

Bu proje, BERT (Bidirectional Encoder Representations from Transformers) modelini kullanarak IMDB film yorumlarÄ± Ã¼zerinde duygu analizi gerÃ§ekleÅŸtiren kapsamlÄ± bir makine Ã¶ÄŸrenmesi uygulamasÄ±dÄ±r.

## ğŸ“‹ Ä°Ã§indekiler

- [Proje HakkÄ±nda](#proje-hakkÄ±nda)
- [Ã–zellikler](#Ã¶zellikler)
- [Kurulum](#kurulum)
- [KullanÄ±m](#kullanÄ±m)
- [Veri Seti](#veri-seti)
- [Model Mimarisi](#model-mimarisi)
- [SonuÃ§lar](#sonuÃ§lar)
- [Teknolojiler](#teknolojiler)
- [KatkÄ±da Bulunma](#katkÄ±da-bulunma)
- [Lisans](#lisans)

## ğŸ¯ Proje HakkÄ±nda

Bu proje, doÄŸal dil iÅŸleme (NLP) alanÄ±nda transformatÃ¶r mimarilerinin gÃ¼cÃ¼nÃ¼ gÃ¶stermek amacÄ±yla geliÅŸtirilmiÅŸtir. BERT modelini kullanarak IMDB film yorumlarÄ±nÄ±n pozitif mi yoksa negatif mi olduÄŸunu yÃ¼ksek doÄŸrulukla tahmin edebilen bir sistem oluÅŸturulmuÅŸtur.

### Ana Hedefler
- BERT modelinin metin sÄ±nÄ±flandÄ±rma performansÄ±nÄ± pratik bir Ã¶rnekle gÃ¶stermek
- Derin Ã¶ÄŸrenme projesinin tÃ¼m adÄ±mlarÄ±nÄ± kapsamlÄ± ÅŸekilde uygulamak
- Hugging Face ekosisteminin etkin kullanÄ±mÄ±nÄ± Ã¶rneklemek
- Modern NLP tekniklerini anlaÅŸÄ±lÄ±r bir formatta sunmak

## âœ¨ Ã–zellikler

- **YÃ¼ksek Performans**: %92+ test doÄŸruluÄŸu ve 0.975+ AUC skoru
- **KapsamlÄ± DeÄŸerlendirme**: DetaylÄ± metrik hesaplamalarÄ± ve gÃ¶rselleÅŸtirmeler
- **Profesyonel Ä°mplementasyon**: Epoch bazÄ±nda model izleme ve otomatik en iyi model seÃ§imi
- **HÄ±z Optimizasyonu**: GPU desteÄŸi ile hÄ±zlÄ± eÄŸitim ve Ã§Ä±karÄ±m
- **GÃ¶rsel Analiz**: KarmaÅŸÄ±klÄ±k matrisi, ROC eÄŸrisi ve eÄŸitim grafikleri
- **SaÄŸlam AltyapÄ±**: Versiyon uyumluluÄŸu saÄŸlanmÄ±ÅŸ kÃ¼tÃ¼phane ortamÄ±

## ğŸš€ Kurulum

### Gereksinimler

Bu proje Google Colab Ã¼zerinde Ã§alÄ±ÅŸacak ÅŸekilde optimize edilmiÅŸtir. AÅŸaÄŸÄ±daki kÃ¼tÃ¼phane versiyonlarÄ± test edilmiÅŸtir:

```python
# Temel gereksinimler
numpy==1.26.4
datasets==3.6.0
transformers==4.48.3
scikit-learn
matplotlib
seaborn
torch
pandas
```

### AdÄ±m AdÄ±m Kurulum

1. **Colab OrtamÄ±nÄ± HazÄ±rlayÄ±n**
   ```python
   # Ã‡alÄ±ÅŸma zamanÄ±nÄ± tamamen sÄ±fÄ±rlayÄ±n
   # Runtime -> Disconnect and delete runtime
   ```

2. **KÃ¼tÃ¼phaneleri Kurun**
   ```python
   # Notebook'un HÃ¼cre 1'ini Ã§alÄ±ÅŸtÄ±rÄ±n
   !pip install numpy==1.26.4 -q
   !pip install datasets==3.6.0 -q
   !pip install transformers==4.48.3 -q
   !pip install scikit-learn matplotlib seaborn -q
   ```

3. **Ã‡alÄ±ÅŸma ZamanÄ±nÄ± Yeniden BaÅŸlatÄ±n**
   ```
   Runtime -> Restart runtime
   ```

4. **GPU'yu AktifleÅŸtirin**
   ```
   Runtime -> Change runtime type -> Hardware accelerator -> GPU
   ```

## ğŸ’» KullanÄ±m

### Temel Ã‡alÄ±ÅŸtÄ±rma

1. Notebook'u Google Colab'da aÃ§Ä±n
2. HÃ¼creleri sÄ±rasÄ±yla Ã§alÄ±ÅŸtÄ±rÄ±n:
   - **HÃ¼cre 1**: KÃ¼tÃ¼phane kurulumu
   - **HÃ¼cre 2**: KÃ¼tÃ¼phane importlarÄ± ve versiyon kontrolÃ¼
   - **HÃ¼cre 3**: IMDB veri seti yÃ¼kleme
   - **HÃ¼cre 4**: Veri setini eÄŸitim/doÄŸrulama/test olarak ayÄ±rma
   - **HÃ¼cre 5**: BERT tokenizer ile tokenizasyon
   - **HÃ¼cre 6**: Ã–nceden eÄŸitilmiÅŸ BERT modelini yÃ¼kleme
   - **HÃ¼cre 7**: Model eÄŸitimi
   - **HÃ¼cre 8**: Test seti deÄŸerlendirmesi
   - **HÃ¼cre 9**: GÃ¶rselleÅŸtirmeler (KarmaÅŸÄ±klÄ±k matrisi, ROC eÄŸrisi)
   - **HÃ¼cre 10**: EÄŸitim grafikleri
   - **HÃ¼cre 11**: HÄ±z analizi

### Ã–zelleÅŸtirme SeÃ§enekleri

```python
# EÄŸitim parametrelerini deÄŸiÅŸtirmek iÃ§in HÃ¼cre 7'deki deÄŸerleri dÃ¼zenleyin
training_args = TrainingArguments(
    num_train_epochs=3,                    # Epoch sayÄ±sÄ±
    per_device_train_batch_size=16,        # EÄŸitim batch boyutu
    per_device_eval_batch_size=32,         # DeÄŸerlendirme batch boyutu
    max_length=256,                        # Maksimum token uzunluÄŸu
    # ... diÄŸer parametreler
)
```

## ğŸ“Š Veri Seti

### IMDB Film YorumlarÄ± Veri Seti

- **Kaynak**: Hugging Face Datasets Hub
- **Boyut**: 50,000 etiketli yorum (25,000 eÄŸitim + 25,000 test)
- **SÄ±nÄ±flar**: 
  - 0: Negatif duygu (olumsuz yorumlar)
  - 1: Pozitif duygu (olumlu yorumlar)
- **Denge**: Her sÄ±nÄ±ftan eÅŸit sayÄ±da Ã¶rnek (dengeli veri seti)

### Veri BÃ¶lÃ¼mÃ¼

- **EÄŸitim Seti**: 20,000 Ã¶rnek (%80)
- **DoÄŸrulama Seti**: 5,000 Ã¶rnek (%20)  
- **Test Seti**: 25,000 Ã¶rnek (orijinal test seti)

## ğŸ—ï¸ Model Mimarisi

### BERT Modeli DetaylarÄ±

- **Base Model**: `bert-base-uncased`
- **Parametre SayÄ±sÄ±**: ~110 milyon
- **Mimari**: 12 katmanlÄ± Transformer enkoder
- **SÄ±nÄ±flandÄ±rma BaÅŸlÄ±ÄŸÄ±**: 2 Ã§Ä±ktÄ±lÄ± (pozitif/negatif)
- **Tokenizer**: WordPiece tokenizasyon
- **Maksimum Uzunluk**: 256 token

### EÄŸitim YapÄ±landÄ±rmasÄ±

```python
# KullanÄ±lan eÄŸitim parametreleri
- Epoch SayÄ±sÄ±: 3
- EÄŸitim Batch Boyutu: 16
- DeÄŸerlendirme Batch Boyutu: 32
- Ã–ÄŸrenme OranÄ±: 5e-5 (varsayÄ±lan)
- Warmup Steps: 500
- Weight Decay: 0.01
```

## ğŸ“ˆ SonuÃ§lar

### Test Seti PerformansÄ±

| Metrik | DeÄŸer |
|--------|--------|
| **Accuracy** | 92.04% |
| **Precision** | 91.94% |
| **Recall** | 92.15% |
| **F1-Score** | 92.05% |
| **Specificity** | 91.92% |
| **AUC** | 97.58% |

### KarmaÅŸÄ±klÄ±k Matrisi SonuÃ§larÄ±

|  | Tahmin Negatif | Tahmin Pozitif |
|--|----------------|----------------|
| **GerÃ§ek Negatif** | 11,490 (TN) | 1,010 (FP) |
| **GerÃ§ek Pozitif** | 981 (FN) | 11,519 (TP) |

### Performans Metrikleri

- **EÄŸitim SÃ¼resi**: ~22 dakika (NVIDIA L4 GPU)
- **Ã‡Ä±karÄ±m HÄ±zÄ±**: ~3,242 Ã¶rnek/saniye
- **Ã–rnek BaÅŸÄ±na Ã‡Ä±karÄ±m**: ~0.31 milisaniye

## ğŸ› ï¸ Teknolojiler

### Ana KÃ¼tÃ¼phaneler

- **ğŸ¤— Transformers**: BERT modeli ve tokenizer
- **ğŸ¤— Datasets**: Veri seti yÃ¼kleme ve iÅŸleme
- **ğŸ”¥ PyTorch**: Derin Ã¶ÄŸrenme framework'Ã¼
- **ğŸ“Š Scikit-learn**: Metrik hesaplamalarÄ±
- **ğŸ“ˆ Matplotlib/Seaborn**: GÃ¶rselleÅŸtirmeler
- **ğŸ¼ Pandas/NumPy**: Veri manipÃ¼lasyonu

### GeliÅŸtirme OrtamÄ±

- **Platform**: Google Colab
- **GPU**: NVIDIA L4
- **Python**: 3.11+
- **CUDA**: 12.4

## ğŸ¯ Gelecek GeliÅŸtirmeler

- [ ] FarklÄ± BERT varyantlarÄ± (RoBERTa, DeBERTa) ile karÅŸÄ±laÅŸtÄ±rma
- [ ] Hiperparametre optimizasyonu (Grid Search/Random Search)
- [ ] Cross-validation ile daha gÃ¼venilir deÄŸerlendirme
- [ ] Model distillation ile hÄ±z optimizasyonu
- [ ] DiÄŸer dil modelleri ile karÅŸÄ±laÅŸtÄ±rmalÄ± analiz
- [ ] Web arayÃ¼zÃ¼ geliÅŸtirme
- [ ] Real-time duygu analizi API'si

## ğŸ¤ KatkÄ±da Bulunma

Bu projeye katkÄ±da bulunmak istiyorsanÄ±z:

1. Projeyi fork edin
2. Feature branch oluÅŸturun (`git checkout -b feature/yeni-ozellik`)
3. DeÄŸiÅŸikliklerinizi commit edin (`git commit -am 'Yeni Ã¶zellik eklendi'`)
4. Branch'inizi push edin (`git push origin feature/yeni-ozellik`)
5. Pull Request oluÅŸturun

### KatkÄ± AlanlarÄ±

- ğŸ› Bug raporlarÄ± ve dÃ¼zeltmeleri
- ğŸ“ˆ Performans iyileÅŸtirmeleri
- ğŸ“ DokÃ¼mantasyon geliÅŸtirmeleri
- âœ¨ Yeni Ã¶zellik Ã¶nerileri
- ğŸ§ª Test coverage artÄ±rma

## ğŸ“„ Lisans

Bu proje MIT lisansÄ± altÄ±nda lisanslanmÄ±ÅŸtÄ±r. Detaylar iÃ§in `LICENSE` dosyasÄ±na bakÄ±nÄ±z.

## ğŸ™ TeÅŸekkÃ¼rler

- **Hugging Face** ekibine transformers ve datasets kÃ¼tÃ¼phaneleri iÃ§in
- **Google** ekibine BERT modelini aÃ§Ä±k kaynak yapmasÄ± iÃ§in
- **IMDB** veri setini oluÅŸturan araÅŸtÄ±rmacÄ±lara
- **PyTorch** ve **Scikit-learn** topluluklarÄ±na


## ğŸ“ Ä°letiÅŸim

ğŸ› **Bug Report**: GitHub Issues kullanÄ±n  
ğŸ’¡ **Feature Request**: Discussions bÃ¶lÃ¼mÃ¼nden Ã¶nerinizi paylaÅŸÄ±n  
ğŸ“§ E-posta: [mehmetaksoy49@gmail.com]

- Pull Request ile katkÄ±da bulunun
- Projeyi yÄ±ldÄ±zlamayÄ± unutmayÄ±n! â­

---

**Not**: Bu proje eÄŸitim amaÃ§lÄ± geliÅŸtirilmiÅŸtir ve akademik Ã§alÄ±ÅŸmalarda referans olarak kullanÄ±labilir.
